#!/usr/bin/env python
# -*- coding: utf-8 -*-

import argparse, os, pandas as pd
from config import Config
from src import utils
from src import forecast as F
from src import planner as P
from src import planner_opt as POPT
from src import report_llm as RLLM

DEFAULT_PROD_COL = "Product_Number"
DEFAULT_DT_COL = "DateTime"

def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument("--data", type=str, required=True, help="features.py ì¶œë ¥ CSV (feat.csv)")
    ap.add_argument("--out_dir", type=str, default="./outputs")

    # âœ… ëª¨ë¸ ì„ íƒì€ forecast.py ê·œê²©ìœ¼ë¡œ ì •ê·œí™” (tweedie | lgbm)
    ap.add_argument("--model", type=str, default="lgbm",
                    choices=["linear", "xgboost", "lgbm", "elastic", "tweedie"])

    ap.add_argument("--encoding", type=str, default="utf-8")
    ap.add_argument("--daily_capacity", type=int, default=5000)
    ap.add_argument("--min_lot_size", type=int, default=0)
    ap.add_argument("--safety_stock", type=int, default=0)

    # Planner / Reporter
    ap.add_argument("--planner", type=str, default="ortools",
                    choices=["heuristic", "ortools"])
    ap.add_argument("--reporter", type=str, default="llm",
                    choices=["template", "llm"])

    # OR-Tools ì˜µì…˜
    ap.add_argument("--int_production", action="store_true",
                    help="ìƒì‚°ëŸ‰ì„ ì •ìˆ˜ë¡œ ê°•ì œ")

    # ğŸ”§ (êµ¬)ì˜µì…˜ â€” í˜„ì¬ ë²„ì „ì—ì„œ ë¯¸ì‚¬ìš©. í˜¸í™˜ì„± ìœ ì§€ë¥¼ ìœ„í•´ ê²½ê³ ë§Œ ì¶œë ¥
    ap.add_argument("--tune", action="store_true", help="(ë¯¸ì‚¬ìš©) Optuna íŠœë‹")
    ap.add_argument("--use_zeromodel", action="store_true", help="(ë¯¸ì‚¬ìš©) ì œë¡œ ì¸í”Œë ˆ 2ë‹¨ê³„")
    ap.add_argument("--quantiles", nargs="*", type=float, default=[], help="(ë¯¸ì‚¬ìš©) ë¶„ìœ„ìˆ˜")

    # ê²€ì¦/ëˆ„ì¶œ ë°©ì§€ ê´€ë ¨
    ap.add_argument("--split", type=str, default="time", choices=["random", "time", "group"],
                    help="ê²€ì¦ ë¶„í•  ë°©ì‹: time(ê¶Œì¥), group, random")
    ap.add_argument("--prod_col", type=str, default=DEFAULT_PROD_COL)
    ap.add_argument("--dt_col", type=str, default=DEFAULT_DT_COL)
    ap.add_argument("--val_size", type=float, default=0.2)
    ap.add_argument("--seed", type=int, default=42)

    # Tweedie/LGBM í•˜ì´í¼íŒŒë¼ë¯¸í„°
    ap.add_argument("--tweedie_power", type=float, default=1.3)
    ap.add_argument("--alpha", type=float, default=0.5)
    ap.add_argument("--lgbm_estimators", type=int, default=800)
    ap.add_argument("--lgbm_lr", type=float, default=0.05)
    ap.add_argument("--lgbm_leaves", type=int, default=63)
    ap.add_argument("--lgbm_min_child", type=int, default=50)
    ap.add_argument("--lgbm_subsample", type=float, default=0.8)
    ap.add_argument("--lgbm_colsample", type=float, default=0.8)
    ap.add_argument("--lgbm_lambda", type=float, default=5.0)
    ap.add_argument("--lgbm_power", type=float, default=1.3)

    # ë¦¬í¬íŠ¸/ë©”íŠ¸ë¦­ ì €ì¥
    ap.add_argument("--metrics_out", type=str, default=None)
    ap.add_argument("--feature_report", type=str, default=None)
    ap.add_argument("--llm_model", type=str, default="gpt-4o-mini")
    ap.add_argument("--max_chars", type=int, default=16000, help="CSV ìš”ì•½ ì…ë ¥ ê¸¸ì´ ì»·")
    return ap.parse_args()


def normalize_model_name(m: str) -> str:
    """mainì˜ ëª¨ë¸ëª…ì„ forecast.py ê·œê²©ìœ¼ë¡œ ë§¤í•‘."""
    m = (m or "").lower()
    if m in ["tweedie", "linear", "elastic"]:
        if m in ["linear", "elastic"]:
            print("âš ï¸ --model", m, "â†’ 'tweedie'ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.")
        return "tweedie"
    if m in ["lgbm", "xgboost"]:
        if m == "xgboost":
            print("âš ï¸ --model xgboostëŠ” í˜„ì¬ êµ¬í˜„ì—ì„œ 'lgbm'ìœ¼ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.")
        return "lgbm"
    # ê¸°ë³¸
    return "tweedie"


def main():
    args = parse_args()
    cfg = Config(
        daily_capacity=args.daily_capacity,
        min_lot_size=args.min_lot_size,
        safety_stock=args.safety_stock,
        model_type=normalize_model_name(args.model),
        encoding=args.encoding,
    )
    utils.ensure_dir(args.out_dir)

    # ğŸ“ ë¯¸ì‚¬ìš© ì˜µì…˜ ê²½ê³ 
    if args.tune: print("âš ï¸ --tune: í˜„ì¬ ë²„ì „ì—ì„œ ë¯¸ì‚¬ìš©(ë¬´ì‹œ).")
    if args.use_zeromodel: print("âš ï¸ --use_zeromodel: í˜„ì¬ ë²„ì „ì—ì„œ ë¯¸ì‚¬ìš©(ë¬´ì‹œ).")
    if args.quantiles: print("âš ï¸ --quantiles: í˜„ì¬ ë²„ì „ì—ì„œ ë¯¸ì‚¬ìš©(ë¬´ì‹œ).")

    # 1) Load data (feat.csv ê¶Œì¥)
    df = utils.load_data(args.data, encoding=cfg.encoding)
    df.columns = [c.strip() for c in df.columns]

    # 2) íƒ€ê¹ƒ ìë™ íƒìƒ‰ (ì˜ˆìƒ ìˆ˜ì£¼ëŸ‰)
    target_cols = F.find_target_cols(df, ["ì˜ˆìƒ ìˆ˜ì£¼ëŸ‰"])
    if len(target_cols) == 0:
        raise RuntimeError("íƒ€ê¹ƒ(ì˜ˆìƒ ìˆ˜ì£¼ëŸ‰) ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì—´ ì´ë¦„ì— 'ì˜ˆìƒ ìˆ˜ì£¼ëŸ‰'ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
    print("ğŸ¯ Targets:", target_cols)

    # 3) X, y êµ¬ì„±(ëˆ„ì¶œ ë°©ì§€: ë¯¸ë˜ 'ì˜ˆì • ìˆ˜ì£¼ëŸ‰' & ëª¨ë“  'ì˜ˆìƒ ìˆ˜ì£¼ëŸ‰'ì€ Xì—ì„œ ì œì™¸)
    X, y, num_cols, cat_cols, excluded = F.build_xy(df, prod_col=args.prod_col, target_cols=target_cols)

    # 4) ëª¨ë¸ íŒŒì´í”„ë¼ì¸
    model_name = normalize_model_name(args.model)
    lgbm_params = dict(
        tweedie_variance_power=args.lgbm_power,
        n_estimators=args.lgbm_estimators,
        learning_rate=args.lgbm_lr,
        num_leaves=args.lgbm_leaves,
        min_child_samples=args.lgbm_min_child,
        subsample=args.lgbm_subsample,
        colsample_bytree=args.lgbm_colsample,
        reg_lambda=args.lgbm_lambda,
        random_state=args.seed,
    )
    model = F.build_model_pipeline(
        model_name=model_name,
        num_cols=num_cols,
        cat_cols=cat_cols,
        tweedie_power=args.tweedie_power,
        alpha=args.alpha,
        lgbm_params=lgbm_params
    )

    # 5) Train & Validate (split: time/group/random)
    model, metrics_df, X_va, y_va = F.train_validate(
        df_raw=df, X=X, y=y, model=model,
        split=args.split, val_size=args.val_size, seed=args.seed,
        dt_col=args.dt_col, prod_col=args.prod_col
    )
    print("\nğŸ“Š Validation metrics (per target)")
    print(metrics_df.to_string())

    metrics_path = os.path.join(args.out_dir, "forecast_validation_metrics.csv")
    if args.metrics_out:
        metrics_path = args.metrics_out
    utils.save_csv(metrics_df, metrics_path)

    # 6) Feature report (ì„ íƒ)
    if args.feature_report:
        pd.DataFrame({"used_numeric_features": pd.Series(num_cols)}).to_csv(
            args.feature_report, index=False, encoding="utf-8-sig"
        )
        pd.DataFrame({"excluded_features": pd.Series(excluded)}).to_csv(
            args.feature_report.replace(".csv", "_excluded.csv"), index=False, encoding="utf-8-sig"
        )
        print(f"ğŸ’¾ í”¼ì²˜ ë¦¬í¬íŠ¸ ì €ì¥: {args.feature_report} / {args.feature_report.replace('.csv', '_excluded.csv')}")

    # 7) ì „ì²´ ì˜ˆì¸¡ â†’ ì œí’ˆë³„ ì§‘ê³„
    pred_df = F.predict_all(model, X_all=X, prod_col=args.prod_col, target_cols=target_cols)
    forecast_by_product = F.aggregate_by_product(pred_df, args.prod_col)

    forecast_path = os.path.join(args.out_dir, "forecast_by_product.csv")
    utils.save_csv(forecast_by_product, forecast_path)

    # 8) Planning
    if args.planner == "heuristic":
        plan_df = P.plan_production(
            forecast_by_product=forecast_by_product,
            horizons=target_cols,
            prod_col=args.prod_col,
            daily_capacity=cfg.daily_capacity,
            min_lot_size=cfg.min_lot_size,
            safety_stock=cfg.safety_stock
        )
    else:
        plan_df = POPT.optimize_plan(
            forecast_by_product=forecast_by_product,
            horizons=target_cols,
            prod_col=args.prod_col,
            daily_capacity=cfg.daily_capacity,
            min_lot_size=cfg.min_lot_size,
            safety_stock=cfg.safety_stock,
            int_production=args.int_production
        )
    plan_path = os.path.join(args.out_dir, "production_plan.csv")
    utils.save_csv(plan_df, plan_path)

    # 9) Reporting
    if args.reporter == "template":
        raise NotImplementedError("í…œí”Œë¦¿ ë¦¬í¬í„°ëŠ” í˜„ì¬ ì£¼ì„ ì²˜ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. --reporter llmì„ ì‚¬ìš©í•˜ì„¸ìš”.")
    else:
        report_txt = RLLM.build_report_with_llm(
            plan_csv=plan_path,
            forecast_csv=forecast_path,
            metrics_csv=metrics_path,
            model_name=args.llm_model,
            max_chars=args.max_chars
        )
    report_path = os.path.join(args.out_dir, "weekly_report.txt")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report_txt)

    print("[âœ… Done]")
    print(f"- Forecast metrics: {metrics_path}")
    print(f"- Forecast by product: {forecast_path}")
    print(f"- Production plan: {plan_path}")
    print(f"- Weekly report: {report_path}")


if __name__ == "__main__":
    main()